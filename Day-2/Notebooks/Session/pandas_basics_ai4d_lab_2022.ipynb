{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<div>\n",
    "<img  style=\"float: left; padding-right: 100px; width: 350px\" src=\"../images/africa-no-words.png\">\n",
    "    </div>\n",
    "    <br>\n",
    "    <h2 align=\"center\">AI4D-Lab | AI Short Course 2022</h2>\n",
    "<hr>\n",
    "<h4 align=\"center\"><a href=\"https://t.co/IoL5C0LiPX\">Zephania Reuben</a></h4>\n",
    "<h4 align=\"center\">July, 2022</h4>\n",
    "<hr>\n",
    "<h3 align=\"center\">The University of Dodoma - CIVE</h3>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<h3 align=\"center\">DATA MANIPULATION | PANDAS</h3>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Pandas?\n",
    "  - **Pandas** is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python.\n",
    "  \n",
    "  - The two primary data structures of pandas, Series (1-dimensional) and DataFrame (2-dimensional), handle the vast majority of typical use cases in finance, statistics, social science, and many areas of engineering.\n",
    "  - Data frames are tabular, meaning that they are based on rows and columns like you would see in a spreadsheet.\n",
    "  - pandas is built on top of NumPy and is intended to integrate well within a scientific computing environment with many other 3rd party libraries.\n",
    "  \n",
    "#### Here are just a few of the things that pandas does well:\n",
    " - Easy handling of missing data (represented as NaN) in floating point as well as non-floating point data\n",
    " - Size mutability: columns can be inserted and deleted from DataFrame and higher dimensional objects\n",
    " - Automatic and explicit data alignment: objects can be explicitly aligned to a set of labels, or the user cansimply ignore the labels and let Series, DataFrame, etc. automatically align the data for you in computations\n",
    " - Powerful, flexible group by functionality to perform split-apply-combine operations on data sets, for both aggregating and transforming data\n",
    " - Make it easy to convert ragged, differently-indexed data in other Python and NumPy data structures into DataFrame objects\n",
    " - Intelligent label-based slicing, fancy indexing, and subsetting of large data sets\n",
    " - Intuitive merging and joining data sets\n",
    " - Flexible reshaping and pivoting of data sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Installation\n",
    "- conda environment \n",
    " conda install pandas\n",
    "- Installing from PyPI\n",
    "   - python -m pip install pandas\n",
    "- **Installing pandas on Linux**\n",
    " - In the following table, we will present some of the common Linux distributions package names for Matplotlib and the tools we can use to install the package:\n",
    " \n",
    "**Distribution**        |       **Package Name**\n",
    "----------------------  |  -------------------------------\n",
    "Debian or Ubuntu (And other Debian derivatives)                 |  <code>sudo apt-get install python3-pandas</code>\n",
    "Fedora                                                          |  <code>sudo dnf install python3-pandas</code>\n",
    "Red hat                                                         |  <code>sudo yum install python3-pandas</code>\n",
    "Centos/RHEL                                                            |  <code>sudo dnf install python3-pandas</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1.Understanding a pandas DataFrame\n",
    "  - a pandas DataFrame (in a Jupyter Notebook) appears to be nothing more than an ordinary table of data consisting of rows and columns. Hiding beneath the surface are the three components--the index, columns, and data (also known as values) that you must be aware of in order to maximize the DataFrame's full potential.\n",
    "  - Analyze the labeled anatomy of the DataFrame:\n",
    "  - **Note**\n",
    "   - In this Notebook we will be using a **Titanic** dataset.A dataset about passengers in Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The variables that describe the passengers are:**\n",
    "\n",
    "- **PassengerId**: and id given to each traveller on the boat.\n",
    "- **Pclass**: the passenger class. It has three possible values: 1,2,3.\n",
    "- **The Name**: a word or set of words by which a person or thing is usually known.\n",
    "- **The Sex**: males or females considered as separate groups.\n",
    "- **The Age**: the number of years that someone has lived.\n",
    "- **SibSp**: number of siblings and spouses traveling with the passenger.\n",
    "- **Parch**: number of parents and children traveling with the passenger.\n",
    "- **The ticket number**: a number (identifier) piece of paper that shows you have paid for a journey.\n",
    "- **The ticket Fare**: amount paid for a ticket.\n",
    "- **The cabin number**: a number for private room on a ship for a passenger.\n",
    "- **The embarkation**: It has three possible values S,C,Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A DataFrame has two axes: a **vertical axis** (the index) and a **horizontal axis**(the columns). Pandas borrows convention from NumPy and uses the integers 0/1 as another way of referring to the vertical/horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library\n",
    "import pandas as pd\n",
    "\n",
    "#Create url\n",
    "\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data as a DataFrame\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Show first 5 rows\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to notice in this DataFrame\n",
    "\n",
    "- First, in a data frame each row corresponds to one observation (e.g., a passenger) and each column corresponds to one feature (gender, age, etc.). For example, bylooking at the first observation we can see that **Heikkinen, Miss. Laina** stayed in first class, was 26 years old, was female, and survived the disaster.\n",
    "- Second, each column contains a name (e.g., Name, PClass, Age) and each rowcontains an index number (e.g., 0 for the lucky Miss Elisabeth Walton Allen). We will use these to select and manipulate observations and features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Creating a DataFrame\n",
    " - First method :\n",
    "   - Create a dataframe and add columns independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "#Add columns to a DataFrame\n",
    "\n",
    "df['Name'] = ['John','Rebecca','Lisa','Godfrey','Vivan']\n",
    "\n",
    "df['Age'] = [19,16,27,18,91]\n",
    "\n",
    "df['Country'] = ['Kenya','Uganda','Rwanda','Tanzania','Burundi']\n",
    "\n",
    "#show DataFrame\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second method :\n",
    "   - Create a dataframe and add columns at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(columns=['Name','Age','Country'],\n",
    "                  data=[\n",
    "                       ['John',19,'Kenya'],\n",
    "                       ['Rebecca',16,'Uganda'],\n",
    "                       ['Lisa',19,'Rwanda'],\n",
    "                       ['Godfrey',19,'Tanzania'],\n",
    "                       ['Vivan',19,'Burundi']\n",
    "                      ])\n",
    "\n",
    "#show DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Creating a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library\n",
    "import pandas as pd\n",
    "\n",
    "#Create a Series\n",
    "series = pd.Series(index=['Name','Age','Country'],data=['John',19,'Uganda'])\n",
    "\n",
    "#show series\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A series can be used to create a DataFrame as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library\n",
    "import pandas as pd\n",
    "\n",
    "#Create a DataFrame\n",
    "\n",
    "df = pd.DataFrame().append(series,ignore_index=True)\n",
    "\n",
    "#show DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Describing a DataFrame\n",
    "- Describing a DataFrame involve looking at its short summary of descriptive statistical measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load library\n",
    "import pandas as pd\n",
    "\n",
    "#Create url\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "#Load data as a DataFrame\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# show statistics\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also take a look at the number of row and colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame has 891 rows(instances/samples) and 12 colums(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Navigating DataFrames\n",
    "   - You need to select individual data or slices of a DataFrame\n",
    "    - **loc**\n",
    "      - is useful when the index of the DataFrame is a label (e.g., a string).\n",
    "    - **iloc**\n",
    "      - works by looking for the position in the DataFrame. For example, iloc[0] will return the first row regardless of whether the index is an integer or a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select three rows\n",
    "dataframe.iloc[1:4] # also dataframe.iloc[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrames do not need to be numerically indexed. We can set the index of a DataFrame to any value where the value is unique to each row. For example, we can set the index to be passenger names and then select rows using a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                         3\n",
       "Survived                            1\n",
       "Pclass                              3\n",
       "Name           Heikkinen, Miss. Laina\n",
       "Sex                            female\n",
       "Age                                26\n",
       "SibSp                               0\n",
       "Parch                               0\n",
       "Ticket               STON/O2. 3101282\n",
       "Fare                            7.925\n",
       "Cabin                             NaN\n",
       "Embarked                            S\n",
       "Name: Heikkinen, Miss. Laina, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set index \n",
    "\n",
    "dataframe = dataframe.set_index(dataframe['Name'])\n",
    "\n",
    "#use index to slice and show row\n",
    "dataframe.loc['Heikkinen, Miss. Laina']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Selecting Rows Based on Conditionals\n",
    " - Suppose we want to select all women in Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Show top two rows where column 'sex' is 'female'\n",
    "dataframe[dataframe['Sex'] == 'female'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multiple conditions are easy as well. For example, here we select all the rows where the passenger is a female 65 or older:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top two rows where column 'sex' is 'female' and 'age' >=27\n",
    "dataframe[(dataframe['Sex'] == 'female') & (dataframe['Age'] >= 27) ].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.Replacing Values\n",
    " - pandas’ replace is an easy way to find and replace values. For example, we can replace any instance of \"female\" in the Sex column with \"Woman\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Replace values, show two rows\n",
    "dataframe['Sex'].replace(\"female\", \"Woman\").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also replace multiple values at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"female\" and \"male with \"Woman\" and \"Man\"\n",
    "dataframe['Sex'].replace([\"female\", \"male\"], [\"Woman\", \"Man\"]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.Renaming Columns\n",
    "- Rename columns using the rename method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Rename column, show two rows\n",
    "dataframe.rename(columns={'Pclass': 'Passenger Class'}).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that the rename method can accept a dictionary as a parameter. We can use the dictionary to change multiple column names at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns, show two rows\n",
    "dataframe.rename(columns={'Pclass': 'Passenger Class', 'Sex': 'Gender'}).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.Finding the Minimum, Maximum, Sum,Average, and Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "# Calculate statistics\n",
    "print('Maximum:', dataframe['Age'].max())\n",
    "print('Minimum:', dataframe['Age'].min())\n",
    "print('Mean:', dataframe['Age'].mean())\n",
    "print('Sum:', dataframe['Age'].sum())\n",
    "print('Count:', dataframe['Age'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.Finding Unique Values\n",
    " - Use unique to view an array of all unique values in a column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Select unique values\n",
    "dataframe['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alternatively, value_counts will display all unique values with the number of times each value appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.Handling Missing Values\n",
    " - isnull and notnull return booleans indicating whether a value is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass                          Name   Sex  Age  \\\n",
       "5             6         0       3              Moran, Mr. James  male  NaN   \n",
       "17           18         1       2  Williams, Mr. Charles Eugene  male  NaN   \n",
       "\n",
       "    SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
       "5       0      0  330877   8.4583   NaN        Q  \n",
       "17      0      0  244373  13.0000   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "## Select missing values, show two rows\n",
    "dataframe[dataframe['Age'].isnull()].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.Deleting a Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The best way to delete a column is to use drop with the parameter axis=1 (i.e., the column axis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Delete column\n",
    "dataframe.drop('Age', axis=1).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also use a list of column names as the main argument to drop multiple columns at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "dataframe.drop(['Age', 'Sex'], axis=1).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.Deleting a Row\n",
    " - Use a boolean condition to create a new DataFrame excluding the rows you want to delete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Delete rows, show first two rows of output\n",
    "dataframe[dataframe['Sex'] != 'male'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.Dropping Duplicate Rows\n",
    "- Use drop_duplicates, but be mindful of the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "# Drop duplicates, show first two rows of output\n",
    "dataframe.drop_duplicates(keep='last').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.Grouping Rows by Values\n",
    "- groupby is one of the most powerful features in pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create URL\n",
    "url = 'Data/Titanic.csv'\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Group rows by the values of the column 'Sex', calculate mean\n",
    "# of each group\n",
    "dataframe.groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.Concatenating DataFrames\n",
    " - Use concat with axis=0 to concatenate along the row axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Billy</td>\n",
       "      <td>Bonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Bran</td>\n",
       "      <td>Balwner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first      last\n",
       "0  1   Alex  Anderson\n",
       "1  2    Amy  Ackerman\n",
       "2  3  Allen       Ali\n",
       "0  4  Billy    Bonder\n",
       "1  5  Brian     Black\n",
       "2  6   Bran   Balwner"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "data_a = {'id': ['1', '2', '3'],\n",
    "'first': ['Alex', 'Amy', 'Allen'],\n",
    "'last': ['Anderson', 'Ackerman', 'Ali']}\n",
    "dataframe_a = pd.DataFrame(data_a, columns = ['id', 'first', 'last'])\n",
    "\n",
    "# Create DataFrame\n",
    "data_b = {'id': ['4', '5', '6'],\n",
    "'first': ['Billy', 'Brian', 'Bran'],\n",
    "'last': ['Bonder', 'Black', 'Balwner']}\n",
    "dataframe_b = pd.DataFrame(data_b, columns = ['id', 'first', 'last'])\n",
    "\n",
    "# Concatenate DataFrames by rows\n",
    "pd.concat([dataframe_a, dataframe_b], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'> Handling Text Data </h3>\n",
    "\n",
    "Unstructured text data, like the contents of a book or a tweet, is both one of the\n",
    "most interesting sources of features and one of the most complex to handle.\n",
    "\n",
    "#### 1.Cleaning Text\n",
    "- Most basic text cleaning operations should only replace Python’s core string\n",
    "operations, in particular strip, replace, and split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang. By Aishwarya Henriette,',\n",
       " 'Parking And Going. By Karl Gautier',\n",
       " 'Today Is The night. By Jarek Prakash']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = [\" Interrobang. By Aishwarya Henriette\",\"Parking And Going. By Karl Gautier\",\"Today Is The night. By Jarek Prakash\"]\n",
    "# Strip whitespaces\n",
    "strip_whitespace = [string.strip() for string in text_data]\n",
    "# Show text\n",
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang By Aishwarya Henriette,',\n",
       " 'Parking And Going By Karl Gautier',\n",
       " 'Today Is The night By Jarek Prakash']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove periods\n",
    "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]\n",
    "# Show text\n",
    "remove_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTERROBANG BY AISHWARYA HENRIETTE,',\n",
       " 'PARKING AND GOING BY KARL GAUTIER',\n",
       " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function\n",
    "def capitalizer(string: str) -> str:\n",
    "    return string.upper()\n",
    "# Apply function\n",
    "[capitalizer(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Parsing and Cleaning HTML\n",
    "- Use Beautiful Soup’s extensive set of options to parse and extract from HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI4D Lab'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from bs4 import BeautifulSoup\n",
    "# Create some HTML code\n",
    "html = \"\"\"\n",
    "<div class='lab_name'><span style='font-weight:bold'>AI4D</span> Lab</div>\"\n",
    "\"\"\"\n",
    "# Parse html\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "# Find the div with the class \"full_name\", show text\n",
    "soup.find(\"div\", { \"class\" : \"lab_name\" }).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Removing Punctuation\n",
    "- Define a function that uses translate with a dictionary of punctuation\n",
    "characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import unicodedata\n",
    "import sys\n",
    "# Create text\n",
    "text_data = ['Hi!!!! I. Love. This. Song....', '10000% Agree!!!! #LoveIT', 'Right?!?!']\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "if unicodedata.category(chr(i)).startswith('P'))\n",
    "# For each string, remove any punctuation characters\n",
    "[string.translate(punctuation) for string in text_data]\n",
    "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Tokenizing Text\n",
    "- Natural Language Toolkit for Python (NLTK) has a powerful set of text\n",
    "manipulation operations, including word tokenizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nsoma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/nsoma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/nsoma/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Create text\n",
    "string = \"The science of today is the technology of tomorrow\"\n",
    "# Tokenize words\n",
    "word_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize sentenses\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# Create text\n",
    "string = \"The science of today is the technology of tomorrow. Tomorrow is today.\"\n",
    "# Tokenize sentences\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Removing Stop Words\n",
    "- Given tokenized text data, you want to remove extremely common words (e.g.,\n",
    "a, is, of, on) that contain little informational value. Use NLTK's ```stopwords```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from nltk.corpus import stopwords\n",
    "# You will have to download the set of stop words the first time\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# Create word tokens\n",
    "tokenized_words = ['i','am','going','to','go','to','the','store','and','park']\n",
    "# Load stop words\n",
    "stop_words = stopwords.words('english')\n",
    "# Remove stop words\n",
    "[word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show stop words\n",
    "stop_words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Stemming Words\n",
    "- You have tokenized words and want to convert them into their root forms. Use NLTK's ```PorterStemmer:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# Create word tokens\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "# Create stemmer\n",
    "porter = PorterStemmer()\n",
    "# Apply stemmer\n",
    "[porter.stem(word) for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Tagging Parts of Speech\n",
    "- You have text data and want to tag each word or character with its part of\n",
    "speech. Use NLTK's ```pre-trained parts-of-speech tagger:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 'NNP'), ('loved', 'VBD'), ('outdoor', 'RP'), ('running', 'VBG')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "# Create text\n",
    "text_data = \"Chris loved outdoor running\"\n",
    "# Use pre-trained part of speech tagger\n",
    "text_tagged = pos_tag(word_tokenize(text_data))\n",
    "# Show parts of speech\n",
    "text_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Encoding Text as a Bag of Words\n",
    "- You have text data and want to create a set of features indicating the number oftimes an observation’s text contains a particular word. Use scikit-learn's ```CountVectorizer:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "'Sweden is best',\n",
    "'Germany beats both'])\n",
    "# Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "# Show feature matrix\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love',\n",
       "       'sweden'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature names\n",
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Weighting Word Importance\n",
    "- You want a bag of words, but with words weighted by their importance to an\n",
    "observation.. Compare the frequency of the word in a document (a tweet, movie review,\n",
    "speech transcript, etc.) with the frequency of the word in all other documents\n",
    "using term frequency-inverse document frequency (tf-idf). scikit-learn makes\n",
    "this easy with  ```TfidfVectorizer:```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!', 'Sweden is best', 'Germany beats both'])\n",
    "# Create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "# Show tf-idf feature matrix\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show tf-idf feature matrix as dense matrix\n",
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature names\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\">Referencies</h3>\n",
    "\n",
    "- Machine Learning with Python\n",
    "Cookbook,Chris Albon, O’Reilly Media, Inc,2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
